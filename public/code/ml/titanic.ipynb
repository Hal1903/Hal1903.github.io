{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb414b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: kagglesdk<1.0,>=0.1.14 in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (0.1.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (6.33.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2025.11.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\haruku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "019adc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b115642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "from kagglehub import dataset_load, KaggleDatasetAdapter\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"yasserh/titanic-dataset\",\n",
    "    \"Titanic-Dataset.csv\"\n",
    ")\n",
    "df_original = df.copy()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2f74ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived=342\n",
      "dead=549\n"
     ]
    }
   ],
   "source": [
    "print(f'survived={len(df[df[\"Survived\"]==1])}')\n",
    "print(f'dead={len(df[df[\"Survived\"]==0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34bbac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Entries: 891\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"Entries:\", len(df)) # 891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3933859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute by median and mode\n",
    "# df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4bd90ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q'] ['A/5 21171' 'PC 17599' 'STON/O2. 3101282' '113803' '373450' '330877'\n",
      " '17463' '349909' '347742' '237736' 'PP 9549' '113783' 'A/5. 2151'\n",
      " '347082' '350406' '248706' '382652' '244373' '345763' '2649' '239865'\n",
      " '248698' '330923' '113788' '347077' '2631' '19950' '330959' '349216'\n",
      " 'PC 17601' 'PC 17569' '335677' 'C.A. 24579' 'PC 17604' '113789' '2677'\n",
      " 'A./5. 2152' '345764' '2651' '7546' '11668' '349253' 'SC/Paris 2123'\n",
      " '330958' 'S.C./A.4. 23567' '370371' '14311' '2662' '349237' '3101295'\n",
      " 'A/4. 39886' 'PC 17572' '2926' '113509' '19947' 'C.A. 31026' '2697'\n",
      " 'C.A. 34651' 'CA 2144' '2669' '113572' '36973' '347088' 'PC 17605' '2661'\n",
      " 'C.A. 29395' 'S.P. 3464' '3101281' '315151' 'C.A. 33111' 'S.O.C. 14879'\n",
      " '2680' '1601' '348123' '349208' '374746' '248738' '364516' '345767'\n",
      " '345779' '330932' '113059' 'SO/C 14885' '3101278' 'W./C. 6608'\n",
      " 'SOTON/OQ 392086' '343275' '343276' '347466' 'W.E.P. 5734' 'C.A. 2315'\n",
      " '364500' '374910' 'PC 17754' 'PC 17759' '231919' '244367' '349245'\n",
      " '349215' '35281' '7540' '3101276' '349207' '343120' '312991' '349249'\n",
      " '371110' '110465' '2665' '324669' '4136' '2627' 'STON/O 2. 3101294'\n",
      " '370369' 'PC 17558' 'A4. 54510' '27267' '370372' 'C 17369' '2668'\n",
      " '347061' '349241' 'SOTON/O.Q. 3101307' 'A/5. 3337' '228414' 'C.A. 29178'\n",
      " 'SC/PARIS 2133' '11752' '7534' 'PC 17593' '2678' '347081'\n",
      " 'STON/O2. 3101279' '365222' '231945' 'C.A. 33112' '350043' '230080'\n",
      " '244310' 'S.O.P. 1166' '113776' 'A.5. 11206' 'A/5. 851' 'Fa 265302'\n",
      " 'PC 17597' '35851' 'SOTON/OQ 392090' '315037' 'CA. 2343' '371362'\n",
      " 'C.A. 33595' '347068' '315093' '363291' '113505' 'PC 17318' '111240'\n",
      " 'STON/O 2. 3101280' '17764' '350404' '4133' 'PC 17595' '250653' 'LINE'\n",
      " 'SC/PARIS 2131' '230136' '315153' '113767' '370365' '111428' '364849'\n",
      " '349247' '234604' '28424' '350046' 'PC 17610' '368703' '4579' '370370'\n",
      " '248747' '345770' '3101264' '2628' 'A/5 3540' '347054' '2699' '367231'\n",
      " '112277' 'SOTON/O.Q. 3101311' 'F.C.C. 13528' 'A/5 21174' '250646'\n",
      " '367229' '35273' 'STON/O2. 3101283' '243847' '11813' 'W/C 14208'\n",
      " 'SOTON/OQ 392089' '220367' '21440' '349234' '19943' 'PP 4348' 'SW/PP 751'\n",
      " 'A/5 21173' '236171' '347067' '237442' 'C.A. 29566' 'W./C. 6609' '26707'\n",
      " 'C.A. 31921' '28665' 'SCO/W 1585' '367230' 'W./C. 14263'\n",
      " 'STON/O 2. 3101275' '2694' '19928' '347071' '250649' '11751' '244252'\n",
      " '362316' '113514' 'A/5. 3336' '370129' '2650' 'PC 17585' '110152'\n",
      " 'PC 17755' '230433' '384461' '110413' '112059' '382649' 'C.A. 17248'\n",
      " '347083' 'PC 17582' 'PC 17760' '113798' '250644' 'PC 17596' '370375'\n",
      " '13502' '347073' '239853' 'C.A. 2673' '336439' '347464' '345778'\n",
      " 'A/5. 10482' '113056' '349239' '345774' '349206' '237798' '370373'\n",
      " '19877' '11967' 'SC/Paris 2163' '349236' '349233' 'PC 17612' '2693'\n",
      " '113781' '19988' '9234' '367226' '226593' 'A/5 2466' '17421' 'PC 17758'\n",
      " 'P/PP 3381' 'PC 17485' '11767' 'PC 17608' '250651' '349243'\n",
      " 'F.C.C. 13529' '347470' '29011' '36928' '16966' 'A/5 21172' '349219'\n",
      " '234818' '345364' '28551' '111361' '113043' 'PC 17611' '349225' '7598'\n",
      " '113784' '248740' '244361' '229236' '248733' '31418' '386525'\n",
      " 'C.A. 37671' '315088' '7267' '113510' '2695' '2647' '345783' '237671'\n",
      " '330931' '330980' 'SC/PARIS 2167' '2691' 'SOTON/O.Q. 3101310' 'C 7076'\n",
      " '110813' '2626' '14313' 'PC 17477' '11765' '3101267' '323951' 'C 7077'\n",
      " '113503' '2648' '347069' 'PC 17757' '2653' 'STON/O 2. 3101293' '349227'\n",
      " '27849' '367655' 'SC 1748' '113760' '350034' '3101277' '350052' '350407'\n",
      " '28403' '244278' '240929' 'STON/O 2. 3101289' '341826' '4137' '315096'\n",
      " '28664' '347064' '29106' '312992' '349222' '394140' 'STON/O 2. 3101269'\n",
      " '343095' '28220' '250652' '28228' '345773' '349254' 'A/5. 13032' '315082'\n",
      " '347080' 'A/4. 34244' '2003' '250655' '364851' 'SOTON/O.Q. 392078'\n",
      " '110564' '376564' 'SC/AH 3085' 'STON/O 2. 3101274' '13507' 'C.A. 18723'\n",
      " '345769' '347076' '230434' '65306' '33638' '113794' '2666' '113786'\n",
      " '65303' '113051' '17453' 'A/5 2817' '349240' '13509' '17464'\n",
      " 'F.C.C. 13531' '371060' '19952' '364506' '111320' '234360' 'A/S 2816'\n",
      " 'SOTON/O.Q. 3101306' '113792' '36209' '323592' '315089' 'SC/AH Basle 541'\n",
      " '7553' '31027' '3460' '350060' '3101298' '239854' 'A/5 3594' '4134'\n",
      " '11771' 'A.5. 18509' '65304' 'SOTON/OQ 3101317' '113787' 'PC 17609'\n",
      " 'A/4 45380' '36947' 'C.A. 6212' '350035' '315086' '364846' '330909'\n",
      " '4135' '26360' '111427' 'C 4001' '382651' 'SOTON/OQ 3101316' 'PC 17473'\n",
      " 'PC 17603' '349209' '36967' 'C.A. 34260' '226875' '349242' '12749'\n",
      " '349252' '2624' '2700' '367232' 'W./C. 14258' 'PC 17483' '3101296'\n",
      " '29104' '2641' '2690' '315084' '113050' 'PC 17761' '364498' '13568'\n",
      " 'WE/P 5735' '2908' '693' 'SC/PARIS 2146' '244358' '330979' '2620'\n",
      " '347085' '113807' '11755' '345572' '372622' '349251' '218629'\n",
      " 'SOTON/OQ 392082' 'SOTON/O.Q. 392087' 'A/4 48871' '349205' '2686'\n",
      " '350417' 'S.W./PP 752' '11769' 'PC 17474' '14312' 'A/4. 20589' '358585'\n",
      " '243880' '2689' 'STON/O 2. 3101286' '237789' '13049' '3411' '237565'\n",
      " '13567' '14973' 'A./5. 3235' 'STON/O 2. 3101273' 'A/5 3902' '364848'\n",
      " 'SC/AH 29037' '248727' '2664' '349214' '113796' '364511' '111426'\n",
      " '349910' '349246' '113804' 'SOTON/O.Q. 3101305' '370377' '364512'\n",
      " '220845' '31028' '2659' '11753' '350029' '54636' '36963' '219533'\n",
      " '349224' '334912' '27042' '347743' '13214' '112052' '237668'\n",
      " 'STON/O 2. 3101292' '350050' '349231' '13213' 'S.O./P.P. 751' 'CA. 2314'\n",
      " '349221' '8475' '330919' '365226' '349223' '29751' '2623' '5727' '349210'\n",
      " 'STON/O 2. 3101285' '234686' '312993' 'A/5 3536' '19996' '29750'\n",
      " 'F.C. 12750' 'C.A. 24580' '244270' '239856' '349912' '342826' '4138'\n",
      " '330935' '6563' '349228' '350036' '24160' '17474' '349256' '2672'\n",
      " '113800' '248731' '363592' '35852' '348121' 'PC 17475' '36864' '350025'\n",
      " '223596' 'PC 17476' 'PC 17482' '113028' '7545' '250647' '348124' '34218'\n",
      " '36568' '347062' '350048' '12233' '250643' '113806' '315094' '36866'\n",
      " '236853' 'STON/O2. 3101271' '239855' '28425' '233639' '349201' '349218'\n",
      " '16988' '376566' 'STON/O 2. 3101288' '250648' '113773' '335097' '29103'\n",
      " '392096' '345780' '349204' '350042' '29108' '363294' 'SOTON/O2 3101272'\n",
      " '2663' '347074' '112379' '364850' '8471' '345781' '350047' 'S.O./P.P. 3'\n",
      " '2674' '29105' '347078' '383121' '36865' '2687' '113501' 'W./C. 6607'\n",
      " 'SOTON/O.Q. 3101312' '374887' '3101265' '12460' 'PC 17600' '349203'\n",
      " '28213' '17465' '349244' '2685' '2625' '347089' '347063' '112050'\n",
      " '347087' '248723' '3474' '28206' '364499' '112058' 'STON/O2. 3101290'\n",
      " 'S.C./PARIS 2079' 'C 7075' '315098' '19972' '368323' '367228' '2671'\n",
      " '347468' '2223' 'PC 17756' '315097' '392092' '11774' 'SOTON/O2 3101287'\n",
      " '2683' '315090' 'C.A. 5547' '349213' '347060' 'PC 17592' '392091'\n",
      " '113055' '2629' '350026' '28134' '17466' '233866' '236852'\n",
      " 'SC/PARIS 2149' 'PC 17590' '345777' '349248' '695' '345765' '2667'\n",
      " '349212' '349217' '349257' '7552' 'C.A./SOTON 34068' 'SOTON/OQ 392076'\n",
      " '211536' '112053' '111369' '370376']\n"
     ]
    }
   ],
   "source": [
    "# which one is easy to do one-hot?\n",
    "print(df[\"Embarked\"].unique(), df[\"Ticket\"].unique())\n",
    "# clearly embarked is easy, and ticket needs some work (not complicated, tho. We can extract the first strings if we want to. Skip for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa07a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"Cabin\"].unique()))\n",
    "df = df.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"]) # drops...\n",
    "# but we can instead do feature engineering for Cabin. Just make a col \"HasCabin\".\n",
    "# we could extract titles, which might be helpful, but we will skip it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90518c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.083345466560417\n",
      "RMSE: 11.530758021014968\n",
      "R2: 0.2828728796800697\n",
      "\n",
      "Median MAE: 10.804195804195805\n",
      "Model MAE: 9.083345466560417\n"
     ]
    }
   ],
   "source": [
    "# We could do median imputation, but try to predict the age and impute them\n",
    "age_df = df.copy() #.drop(columns=[\"Name\", \"Ticket\"])\n",
    "\n",
    "# Encode simple categorical features first\n",
    "age_df = pd.get_dummies(age_df, columns=[\"Sex\", \"Embarked\",], drop_first=True)\n",
    "age_df[\"Age\"] = df_original[\"Age\"] # because we imputed age by median!\n",
    "\n",
    "# Separate known / unknown ages\n",
    "age_known = age_df[age_df[\"Age\"].notnull()]\n",
    "age_unknown = age_df[age_df[\"Age\"].isnull()]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_age = age_known.drop(\"Age\", axis=1)\n",
    "y_age = age_known[\"Age\"]\n",
    "\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(\n",
    "    X_age, y_age, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_age_pred = age_unknown.drop(\"Age\", axis=1)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "# age_model = RandomForestRegressor(n_estimators=200, max_depth=10)\n",
    "age_model = XGBRFRegressor()\n",
    "\n",
    "age_model.fit(X_train_age, y_train_age)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred_age = age_model.predict(X_test_age)\n",
    "\n",
    "mae = mean_absolute_error(y_test_age, y_pred_age)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_age, y_pred_age))\n",
    "r2 = r2_score(y_test_age, y_pred_age)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "median_pred = np.full_like(y_test_age, y_train_age.median())\n",
    "median_mae = mean_absolute_error(y_test_age, median_pred)\n",
    "\n",
    "print(\"\\nMedian MAE:\", median_mae)\n",
    "print(\"Model MAE:\", mae)\n",
    "\n",
    "if mae <= median_mae:\n",
    "    predicted_ages = age_model.predict(X_age_pred)\n",
    "    df.loc[age_unknown.index, \"Age\"] = predicted_ages\n",
    "else:\n",
    "    median_age = y_train_age.median() # avoiding data leakage\n",
    "    df.loc[age_unknown.index, \"Age\"] = median_age\n",
    "    \n",
    "# 1 year improvement. Maybe this way imputation is slightly more effective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "638dc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99f49121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Fare', 'Embarked', 'FamilySize', 'IsAlone'],\n",
      "      dtype='object')\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Fare           float64\n",
      "Embarked        object\n",
      "FamilySize       int64\n",
      "IsAlone          int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcbf4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_cols = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"Sex\", \"Embarked\"], drop_first=True)\n",
    "\n",
    "y = df[\"Survived\"]\n",
    "X = df.drop(columns=[\"Survived\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "866ab5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 11), (891,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3d7d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6868a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_eval_predict(X_train, y_train, X_test, y_test):\n",
    "    # Training\n",
    "    model = RandomForestClassifier(n_estimators=100, criterion='log_loss', max_depth=32)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm,\n",
    "        index=[\"Actual 0\", \"Actual 1\"],\n",
    "        columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "    )\n",
    "\n",
    "    print(cm_df, end=\"\\n\\n\")\n",
    "\n",
    "    # more conveniently, this method works\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1278896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted 0  Predicted 1\n",
      "Actual 0          117           20\n",
      "Actual 1           27           59\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       137\n",
      "           1       0.75      0.69      0.72        86\n",
      "\n",
      "    accuracy                           0.79       223\n",
      "   macro avg       0.78      0.77      0.77       223\n",
      "weighted avg       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = train_eval_predict(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median imputation\n",
    "#           Predicted 0  Predicted 1\n",
    "# Actual 0          117           20\n",
    "# Actual 1           27           59\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.81      0.85      0.83       137\n",
    "#            1       0.75      0.69      0.72        86\n",
    "\n",
    "# ML-based imputation did not have much effect :(  but that's okay.\n",
    "# Age was weakly correlated. This method could have a stronger impact in other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af84622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7892376681614349\n",
      "Precision: 0.7468354430379747\n",
      "Recall: 0.686046511627907\n",
      "F1 Score: 0.7151515151515152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "# not bad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
