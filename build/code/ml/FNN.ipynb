{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b26c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haruku\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = fetch_openml(\n",
    "    \"mnist_784\",\n",
    "    version=1,\n",
    "    return_X_y=True,\n",
    "    as_frame=False   # ensures numpy arrays instead of pandas\n",
    ")\n",
    "\n",
    "# Convert pixel values to a float type and scale them (optional, but recommended)\n",
    "X = X.astype('float32') / 255.0\n",
    "y = y.astype(int) # converting to int from str\n",
    "\n",
    "# Split data into training and testing sets if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7657e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 784) (52500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28ac428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(X, y))\n",
    "for index, (data, label) in enumerate(images_and_labels[:4]):\n",
    "    imgdim=int(np.sqrt(X[index].shape[0]))\n",
    "    img=np.reshape(X[index],(imgdim,imgdim))\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r)\n",
    "    plt.title(f'Training: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1283723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --------------------------------\n",
    "# 2. Define Models\n",
    "# --------------------------------\n",
    "\n",
    "models = {\n",
    "    # Tuned MLP (light tuning, no CV)\n",
    "    \"MLP\": MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 256),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=3000,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1892ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n",
      "\n",
      "Model Comparison:\n",
      "\n",
      "  Model  Accuracy\n",
      "0   MLP    0.9776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Train & Evaluate (may take 3-6 min for XGB)\n",
    "# --------------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5566e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc62a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Define a transform to convert the data to tensors and normalize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size(0) return (batch_size, channels, height, width) -- for MNIST x.shape = (64, 1, 28, 28)\n",
    "        # x.view(x.size(0), -1)  # x.view reshapes/flattens batch properly. -1 to determine the dimension automatically.\n",
    "        # # but, sklearn mnist is already flattened! so we don't need x.view(...). For torchvision mnist data, we do. \n",
    "        x = self.network(x)\n",
    "        return x\n",
    "model = FNN()\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aa43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long) # long is required for CrossEntropy\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "model = FNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a182a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes implementation easier and training more efficient\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f9cd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # switch to gpu if available\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60418a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0845\n",
      "Epoch 20, Loss: 0.0872\n",
      "Epoch 30, Loss: 0.0839\n",
      "Epoch 40, Loss: 0.0804\n",
      "Epoch 50, Loss: 0.0743\n",
      "Epoch 60, Loss: 0.0751\n",
      "Epoch 70, Loss: 0.0728\n",
      "Epoch 80, Loss: 0.0685\n",
      "Epoch 90, Loss: 0.0690\n",
      "Epoch 100, Loss: 0.0661\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    if epoch % 10 == 9:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a9aa42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.23%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# almost indifferent from sklearn MLP, expected.\n",
    "# sklearn is more optimized and we set \"early stopping\"\n",
    "# you may try adding this feature to our training!\n",
    "# You should know how to use PyTorch for machine/deep learning; \n",
    "# next article will introduce you more advanced architecture to handle image processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
